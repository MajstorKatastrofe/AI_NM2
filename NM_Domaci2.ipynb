{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMx2xlpDzPV0tavcibMtTS8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MajstorKatastrofe/AI_NM2/blob/main/NM_Domaci2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n"
      ],
      "metadata": {
        "id": "wElyKQDCB44R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations to apply to the data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])"
      ],
      "metadata": {
        "id": "cMHzC7-HB51I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion-MNIST dataset\n",
        "trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
        "                                            download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
        "                                           download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64,\n",
        "                                         shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "5drt7LcICMT8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "           'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot')\n"
      ],
      "metadata": {
        "id": "wgKqqMm6CQI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 4 * 4)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aVyDj1HLCTMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "uEmcPD5UCWoz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 100 == 99:    # print every 100 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 100))\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkEk0VEoAMrr",
        "outputId": "468dd3ff-8547-4d88-ad6c-f4ba9fe6ca9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 2.302\n",
            "[1,   200] loss: 2.298\n",
            "[1,   300] loss: 2.290\n",
            "[1,   400] loss: 2.278\n",
            "[1,   500] loss: 2.253\n",
            "[1,   600] loss: 2.181\n",
            "[1,   700] loss: 1.897\n",
            "[1,   800] loss: 1.362\n",
            "[1,   900] loss: 1.042\n",
            "[2,   100] loss: 0.862\n",
            "[2,   200] loss: 0.809\n",
            "[2,   300] loss: 0.761\n",
            "[2,   400] loss: 0.728\n",
            "[2,   500] loss: 0.696\n",
            "[2,   600] loss: 0.685\n",
            "[2,   700] loss: 0.662\n",
            "[2,   800] loss: 0.697\n",
            "[2,   900] loss: 0.656\n",
            "[3,   100] loss: 0.655\n",
            "[3,   200] loss: 0.637\n",
            "[3,   300] loss: 0.612\n",
            "[3,   400] loss: 0.602\n",
            "[3,   500] loss: 0.598\n",
            "[3,   600] loss: 0.590\n",
            "[3,   700] loss: 0.580\n",
            "[3,   800] loss: 0.585\n",
            "[3,   900] loss: 0.561\n",
            "[4,   100] loss: 0.568\n",
            "[4,   200] loss: 0.536\n",
            "[4,   300] loss: 0.554\n",
            "[4,   400] loss: 0.555\n",
            "[4,   500] loss: 0.533\n",
            "[4,   600] loss: 0.543\n",
            "[4,   700] loss: 0.534\n",
            "[4,   800] loss: 0.521\n",
            "[4,   900] loss: 0.520\n",
            "[5,   100] loss: 0.514\n",
            "[5,   200] loss: 0.514\n",
            "[5,   300] loss: 0.494\n",
            "[5,   400] loss: 0.511\n",
            "[5,   500] loss: 0.511\n",
            "[5,   600] loss: 0.490\n",
            "[5,   700] loss: 0.472\n",
            "[5,   800] loss: 0.482\n",
            "[5,   900] loss: 0.480\n",
            "[6,   100] loss: 0.482\n",
            "[6,   200] loss: 0.476\n",
            "[6,   300] loss: 0.489\n",
            "[6,   400] loss: 0.455\n",
            "[6,   500] loss: 0.474\n",
            "[6,   600] loss: 0.461\n",
            "[6,   700] loss: 0.444\n",
            "[6,   800] loss: 0.451\n",
            "[6,   900] loss: 0.468\n",
            "[7,   100] loss: 0.438\n",
            "[7,   200] loss: 0.437\n",
            "[7,   300] loss: 0.441\n",
            "[7,   400] loss: 0.432\n",
            "[7,   500] loss: 0.446\n",
            "[7,   600] loss: 0.441\n",
            "[7,   700] loss: 0.445\n",
            "[7,   800] loss: 0.438\n",
            "[7,   900] loss: 0.440\n",
            "[8,   100] loss: 0.423\n",
            "[8,   200] loss: 0.413\n",
            "[8,   300] loss: 0.432\n",
            "[8,   400] loss: 0.425\n",
            "[8,   500] loss: 0.426\n",
            "[8,   600] loss: 0.417\n",
            "[8,   700] loss: 0.405\n",
            "[8,   800] loss: 0.400\n",
            "[8,   900] loss: 0.418\n",
            "[9,   100] loss: 0.400\n",
            "[9,   200] loss: 0.410\n",
            "[9,   300] loss: 0.396\n",
            "[9,   400] loss: 0.391\n",
            "[9,   500] loss: 0.407\n",
            "[9,   600] loss: 0.408\n",
            "[9,   700] loss: 0.392\n",
            "[9,   800] loss: 0.397\n",
            "[9,   900] loss: 0.407\n",
            "[10,   100] loss: 0.397\n",
            "[10,   200] loss: 0.384\n",
            "[10,   300] loss: 0.382\n",
            "[10,   400] loss: 0.383\n",
            "[10,   500] loss: 0.384\n",
            "[10,   600] loss: 0.382\n",
            "[10,   700] loss: 0.379\n",
            "[10,   800] loss: 0.380\n",
            "[10,   900] loss: 0.392\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model to evaluation mode\n",
        "net.eval()\n",
        "\n",
        "# Initialize variables to keep track of validation loss and accuracy\n",
        "val_loss = 0.0\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Load the Fashion-MNIST validation dataset\n",
        "val_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "# Iterate over the validation dataset\n",
        "with torch.no_grad():\n",
        "    for data in val_dataloader:\n",
        "        images, labels = data\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = net(images)\n",
        "\n",
        "        # Compute the loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Accumulate the validation loss\n",
        "        val_loss += loss.item()\n",
        "\n",
        "        # Get the predicted labels\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        # Update the total number of samples\n",
        "        total += labels.size(0)\n",
        "\n",
        "        # Count the number of correct predictions\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate the average validation loss\n",
        "avg_val_loss = val_loss / len(val_dataloader)\n",
        "\n",
        "# Calculate the validation accuracy\n",
        "accuracy = correct / total\n",
        "\n",
        "# Print the validation loss and accuracy\n",
        "print('Validation Loss: {:.4f}'.format(avg_val_loss))\n",
        "print('Validation Accuracy: {:.2f}%'.format(100 * accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAa-AvSVFlX2",
        "outputId": "3908d219-c9f0-45b5-bfe2-d90bc601ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.4123\n",
            "Validation Accuracy: 84.97%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model parameters to a file\n",
        "torch.save(net.state_dict(), 'fashion_mnist_cnn.pth')\n"
      ],
      "metadata": {
        "id": "ccFO5vuTHC_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model parameters\n",
        "net.load_state_dict(torch.load('fashion_mnist_cnn.pth'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAPsdChwGrBk",
        "outputId": "94137d2d-3259-468d-b88a-2196bee11267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model on one photo from each category\n",
        "with torch.no_grad():\n",
        "    category_predictions = {}\n",
        "    for images, labels in testloader:\n",
        "        for image, label in zip(images, labels):\n",
        "            category = classes[label.item()]\n",
        "            if category not in category_predictions:\n",
        "                # Get the predicted label\n",
        "                outputs = net(image.unsqueeze(0))\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                predicted_label = classes[predicted.item()]\n",
        "\n",
        "                # Store the predicted label for this category\n",
        "                category_predictions[category] = predicted_label\n",
        "\n",
        "                # Print the result\n",
        "                print(f\"Category: {category}, Predicted Label: {predicted_label}\")\n",
        "\n",
        "            # Stop if we have one prediction for each category\n",
        "            if len(category_predictions) == len(classes):\n",
        "                break\n",
        "\n",
        "        # Stop if we have one prediction for each category\n",
        "        if len(category_predictions) == len(classes):\n",
        "            break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThwlYMa6HGqC",
        "outputId": "4d0711e4-2645-48de-d8bf-4d429f4d7866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category: Ankle boot, Predicted Label: Ankle boot\n",
            "Category: Pullover, Predicted Label: Pullover\n",
            "Category: Trouser, Predicted Label: Trouser\n",
            "Category: Shirt, Predicted Label: Shirt\n",
            "Category: Coat, Predicted Label: Coat\n",
            "Category: Sandal, Predicted Label: Sandal\n",
            "Category: Sneaker, Predicted Label: Sneaker\n",
            "Category: Dress, Predicted Label: Dress\n",
            "Category: Bag, Predicted Label: Bag\n",
            "Category: T-shirt/top, Predicted Label: T-shirt/top\n"
          ]
        }
      ]
    }
  ]
}